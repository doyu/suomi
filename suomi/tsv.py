"""TSV file generation and manipulation functions"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_tsv.ipynb.

# %% auto 0
__all__ = ['texts2tsv', 'cattsv', 'update_tsv_media_paths']

# %% ../nbs/01_tsv.ipynb 2
import os
import csv
import re
import warnings
from pathlib import Path
from .core import ffr
from .xlate import xtexts

# %% ../nbs/01_tsv.ipynb 3
def texts2tsv(
    texts: list[str],  # List of Finnish texts to translate
    output_path: str,  # Output TSV file path (e.g., "tsvs/06_Ruoka.tsv")
    tags: str | list[str] = "lang::fi"  # Tags (string or list), lang::fi auto-included
) -> None:
    """
    Main function: translate Finnish words and create TSV file.
    Example:
        >>> texts = ["omena", "banaani", "Minä syön omenaa"]
        >>> texts2tsv(texts, "tsvs/06_Ruoka.tsv", tags="src::daily")
        >>> texts2tsv(texts, "tsvs/06_Ruoka.tsv", tags=["src::class", "level::A1"])
    """
    # Process tags
    if isinstance(tags, str):
        tag_list = [t.strip() for t in tags.split(",")]
    else:
        tag_list = list(tags)
    
    # Always ensure lang::fi is included
    if "lang::fi" not in tag_list:
        tag_list.insert(0, "lang::fi")
    
    # Convert to comma-separated string for TSV
    tag_string = ",".join(tag_list)
    
    xsls = xtexts(texts)
    out = Path(output_path)
    out.parent.mkdir(parents=True, exist_ok=True)   
    with open(out, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=["Finnish", "English", "Japanese", "mp3_path", "img_path", "tags"],
            delimiter="\t"
        )
        writer.writeheader()
        for x in xsls:
            x["tags"] = tag_string  # Add tags to each row
            writer.writerow(x)

# %% ../nbs/01_tsv.ipynb 4
def cattsv(
    fname: str,  # Path to TSV file
    skip_empty: bool = False  # Skip empty rows
) -> tuple[list[dict], list[str], int]:
    """Read TSV file and return (rows, fieldnames, num_entries) tuple.
    
    Caller can unpack as needed:
        rows = cattsv(fname)[0]  # Just rows
        rows, fields, num = cattsv(fname)  # All metadata
    """
    rows = []   
    with open(fname, "r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f, delimiter="\t")
        fields = list(reader.fieldnames) if reader.fieldnames else []
        
        for row in reader:
            if skip_empty and not any(row.values()):
                continue
            rows.append(row)
    
    return rows, fields, len(rows)

# %% ../nbs/01_tsv.ipynb 7
def _assign_files_by_row(
    all_files: list[str],  # All files found matching stem prefix
    stem: str,             # File stem (TSV filename without extension)
    extensions: list[str], # List of extensions to process (e.g., [".mp3"] or [".png", ".jpg"])
    num_rows: int,         # Number of rows in TSV (determines result list length)
) -> list[str]:            # List of file paths, one per row (empty string if not found)
    """Assign files to rows based on naming conventions.
    
    File naming rules:
    - Row-specific: {stem}_NN.ext (e.g., "06_Daily_00.mp3" for row 0)
    - Common: {stem}.ext (e.g., "06_Daily.png" for all rows)
    
    Behavior:
    - First tries row-specific files ({stem}_NN.ext)
    - If row-specific not found and common file ({stem}.ext) exists, uses common file
    - If neither found, returns empty string
    
    For multiple extensions (e.g., [".png", ".jpg"]), uses first found in order.
    
    Returns a list of length num_rows where index i corresponds to row i.
    """
    import re
    
    # Build extension pattern
    ext_pat = '|'.join(re.escape(ext.lstrip('.')) for ext in extensions)
    row_pat = re.compile(rf"^{re.escape(stem)}_(\d+)\.({ext_pat})$", re.IGNORECASE)
    common_pat = re.compile(rf"^{re.escape(stem)}\.({ext_pat})$", re.IGNORECASE)
    
    # Classify files
    by_row = {}  # {row_idx: {ext: path}}
    common = {}  # {ext: path}
    
    for path in all_files:
        name = Path(path).name
        m = row_pat.match(name)
        if m:
            idx, ext = int(m.group(1)), "." + m.group(2).lower()
            by_row.setdefault(idx, {})[ext] = path
        else:
            # Check if it's a common file
            m = common_pat.match(name)
            if m:
                common["." + m.group(1).lower()] = path
    # Assign files to rows (respecting extension priority)
    # Use common files only if they exist (determined by whether common dict has entries)
    result = []
    for i in range(num_rows):
        path = ""
        # First try row-specific files
        if i in by_row:
            for ext in extensions:
                if ext in by_row[i]:
                    path = by_row[i][ext]
                    break
        # If not found and common files exist, try common files
        if not path and common:
            for ext in extensions:
                if ext in common:
                    path = common[ext]
                    break
        result.append(path)
    
    return result

# %% ../nbs/01_tsv.ipynb 8
def update_tsv_media_paths(
    tsv: str,               # Path to TSV file
    dirs: list[str] = ["audio", "images"], # Directories to search for media files
) -> None:
    """Update TSV file with mp3 and image paths based on file name conventions.
    
    Searches for media files matching the TSV filename stem and assigns them to rows.
    Only non-empty rows are counted as entries (empty rows are skipped).
    
    File naming rules (where {stem} = TSV filename without extension, NN = zero-padded row index):
    
    MP3 files (row-specific only):
    - Pattern: {stem}_NN.mp3 (e.g., "05_Keho_00.mp3" for row 0)
    - Priority: {stem}_NN.mp3 → "" (common files not used for MP3)
    - Searches in: dirs (recursively)
    
    Image files (row-specific + common fallback):
    - Row-specific: {stem}_NN.{png,jpg} (e.g., "05_Keho_00.png" for row 0)
       - If exists, use this (common files are ignored)
    - Common: {stem}.{png,jpg} (e.g., "05_Keho.png" for all rows)
       - Only used if row-specific file not found
    - Priority: {stem}_NN.png > {stem}_NN.jpg > {stem}.png > {stem}.jpg > ""
    - Searches in: dirs (recursively)
    
    Examples:
        >>> update_tsv_media_paths("tsvs/05_Keho.tsv")
        # For row 0:
        # - MP3: "05_Keho_00.mp3" if exists, else ""
        # - Image: "05_Keho_00.png" if exists, else "05_Keho_00.jpg" if exists,
        #          else "05_Keho.png" if exists, else "05_Keho.jpg" if exists, else ""
    """
    tsv_path = Path(tsv)
    stem = tsv_path.stem
    all_files = ffr(dirs, [".mp3", ".png", ".jpg"], prefix=stem)
    
    # Read TSV to get rows, fieldnames, and entry count (skipping empty rows)
    rows, fields, num_entries = cattsv(tsv, skip_empty=True)
    
    # Assign files using common helper function (based on actual entry count)
    # MP3: row-specific only (common files won't match .mp3 pattern in practice)
    mp3_files = _assign_files_by_row(all_files, stem, [".mp3"], num_entries)
    
    # Images: row-specific + common fallback, png > jpg priority
    img_files = _assign_files_by_row(all_files, stem, [".png", ".jpg"], num_entries)

    if num_entries > 100:
        warnings.warn(
            f"TSV '{tsv}' has {num_entries} entries; ensure mp3/image files exist for indexes >= 100.",
            stacklevel=2,
        )

    
    # Update rows with file paths (using enumerate to match entry indices)
    for i, row in enumerate(rows):
        row['mp3_path'] = mp3_files[i]
        row['img_path'] = img_files[i]
    
    # Write updated TSV
    with open(tsv, "w", encoding="utf-8", newline="") as f:
        w = csv.DictWriter(f, fieldnames=fields, delimiter="\t")
        w.writeheader()
        w.writerows(rows)
